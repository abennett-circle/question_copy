{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports system and makes necessary addition to path\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "# Imports the questionnaire filler\n",
        "from src.Questionnaire_Filler import Questionnaire_Filler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In README.md, need to do:\n",
        "Setup your python environment (how to install requirements.txt)\n",
        "How to run the unit tests\n",
        "How to run a command line example (including using defaults in the code)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sets up the questionnaire filler object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the questionnaire filler\n",
        "filler = Questionnaire_Filler(\n",
        "    reference_file_name=\"data/Mock_Reference.csv\",\n",
        "    reference_question_col=\"Question\",\n",
        "    reference_answer_col=\"Answer\",\n",
        "    unanswered_file_name=\"data/Mock_Unanswered.csv\",\n",
        "    unanswered_question_col=\"Question\",\n",
        "    unanswered_answer_col=\"Answer\",\n",
        "    default_model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matches the Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully parsed 9 question matches\n",
            "Processing 8 items for answer matching\n",
            "Successfully parsed answer match scores for 8 items\n",
            "\n",
            "Dissimilar Questions between the reference and unanswered questionnaires:\n",
            "\n",
            "Matched: What's pirates favorite letter?\n",
            "To: What be a pirates favorite letter?\n",
            "Similarity: 0.95\n",
            "\n",
            "\n",
            "\n",
            "Matched: What is the airspeed velocity of an unladen swallow?\n",
            "To: What is the velocity of an unladen swallow?\n",
            "Similarity: 0.9\n",
            "\n",
            "\n",
            "\n",
            "Matched: Do you have a quest or journey?\n",
            "To: What is your quest?\n",
            "Similarity: 0.8\n",
            "\n",
            "\n",
            "\n",
            "Matched: What is the worst football team ever? And I want you to speak freely my guy.\n",
            "To: What is the worst football team ever?\n",
            "Similarity: 0.85\n",
            "\n",
            "\n",
            "\n",
            "No match found for: Why are there so many songs about rainbows and what's on the other side?\n",
            "\n",
            "\n",
            "\n",
            "Matched: Cuantos a√±os tienes?\n",
            "To: How old are you?\n",
            "Similarity: 0.9\n",
            "\n",
            "\n",
            "\n",
            "Matched: What is the best american football team to ever exist?\n",
            "To: What is the best american football team ever?\n",
            "Similarity: 0.9\n",
            "\n",
            "\n",
            "\n",
            "Matched: What is your like favorite shade of color?\n",
            "To: What is your favorite color?\n",
            "Similarity: 0.8\n",
            "\n",
            "\n",
            "\n",
            "Matched: What's your name?\n",
            "To: What is your name?\n",
            "Similarity: 0.95\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fill the questionnaire with matched answers\n",
        "matches = filler._fill_best_matches()\n",
        "\n",
        "print (\"\\nDissimilar Questions between the reference and unanswered questionnaires:\\n\")\n",
        "\n",
        "# Review the matches\n",
        "for match in matches:\n",
        "    if match.get(\"no_match\", False):\n",
        "        print(f\"No match found for: {match['unmatched_question']}\")\n",
        "        print(\"\\n\\n\")\n",
        "    else:\n",
        "        print(f\"Matched: {match['unmatched_question']}\")\n",
        "        print(f\"To: {match['match']['matched_question']}\")\n",
        "        print(f\"Similarity: {match['match']['similarity']}\")\n",
        "        print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generates the combined questionnaire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined questionnaire has been saved to combined_questionnaire.csv!\n"
          ]
        }
      ],
      "source": [
        "filler.generate_combined_questionnaire()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
